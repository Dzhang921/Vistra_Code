{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the excel file\n",
    "raw_data = pd.read_excel('Wind_data.xlsx', sheet_name='Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Date Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum and maximum time of the data\n",
    "min_time = raw_data['DATETIME'].min()\n",
    "max_time = raw_data['DATETIME'].max()\n",
    "\n",
    "# Create a list for output holder\n",
    "time_list = []\n",
    "# Set Starting\n",
    "current = min_time\n",
    "\n",
    "# Loop through the time \n",
    "while current < max_time:\n",
    "    time_list.append(current)\n",
    "    current += timedelta(seconds=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new holding dataframe for merge\n",
    "full_data = pd.DataFrame({\n",
    "    'DATETIME': time_list\n",
    "})\n",
    "\n",
    "# Merge the raw_data with full timeframe\n",
    "full_data = full_data.merge(raw_data,how='left', on=['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the columns to check where is the null\n",
    "for col in full_data.columns[1:]:\n",
    "    # Get the numpy arrange of the column value\n",
    "    work = full_data[col].values\n",
    "    # Create an empty list for holding the final value\n",
    "    fill = [0] * len(work)\n",
    "    # Initiate the null count\n",
    "    cnt = 0\n",
    "    # Loop through the raw value\n",
    "    for i in range(len(work)):\n",
    "        # If not null \n",
    "        if not pd.isnull(work[i]):\n",
    "            # And null count is 0, then we fill in the value into the new list\n",
    "            if cnt == 0:\n",
    "                fill[i] = work[i]\n",
    "            else:\n",
    "                # Else we use the starting point and ending point value to create a smoothing curve for missing value fill\n",
    "                # EX: [0, NaN, 3] filled to be [0, 1.5, 3]\n",
    "                if work[i] != work[i-cnt-1]:\n",
    "                    fill_in_list = np.append(np.arange(work[i-cnt-1], work[i], (work[i]-work[i-cnt-1])/(cnt+1)), work[i])\n",
    "                # Exception Holding for the same value case\n",
    "                else:\n",
    "                    fill_in_list = [work[i]] * (cnt+2)\n",
    "                # Fill in the holding list with the new values\n",
    "                fill[i-cnt:i+1] = fill_in_list[1:]\n",
    "                # Restart the null count\n",
    "                cnt = 0     \n",
    "        else:\n",
    "            # Count adds\n",
    "            cnt+=1\n",
    "    \n",
    "    # Put the values back into the dataframe\n",
    "    if len(work) != len(fill) and fill[-1]==0:\n",
    "        full_data[col] = fill[:-1]\n",
    "    else:\n",
    "        full_data[col] = fill\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the test dataset\n",
    "test_data = pd.read_excel('Wind_data.xlsx', sheet_name='Predict')\n",
    "\n",
    "# Append the test data to the full data\n",
    "train_test_df = pd.concat([full_data, test_data], ignore_index=True)\n",
    "\n",
    "# Get the columns to be normalize\n",
    "full_columns = train_test_df.columns\n",
    "# Only normalize the column starts with WS\n",
    "normalize_col = [x for x in full_columns if x.startswith('WS')]\n",
    "\n",
    "# Normalize & transform the data\n",
    "transformer = Normalizer().fit(train_test_df[normalize_col])\n",
    "train_test_df[normalize_col] = transformer.transform(train_test_df[normalize_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out the training & test dataset\n",
    "normalized_train = train_test_df[~train_test_df['CF'].isnull()].copy()\n",
    "normalized_test = train_test_df[train_test_df['CF'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the preprocessed output\n",
    "normalized_train.to_csv('Prepared_Data/Normalized_Missing_Value_Filled.csv', index=False)\n",
    "normalized_test.to_csv('Prepared_Data/Test_data_normalized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
